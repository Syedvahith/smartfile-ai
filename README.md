![Python](https://img.shields.io/badge/Python-3.10-blue)
![Flask](https://img.shields.io/badge/Framework-Flask-lightgrey)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)
![Ollama](https://img.shields.io/badge/LLM-Mistral-blueviolet)

# ğŸš€ SmartFile AI â€“ Python File Summary & Query Assistant

SmartFile AI is a powerful Python automation tool that downloads, processes, and summarizes CSV files using open-source LLMs (like Mistral or LLaMA3 via Ollama), with a beautiful dark/light UI.

---

## âœ¨ Features

- âœ… Download data from API and Web (Selenium)
- âœ… Auto clean & rename CSVs
- âœ… Use open-source LLMs (like Mistral) for AI-powered summaries
- âœ… Ask any natural language question on the file (Q&A)
- âœ… HTML report generator
- ğŸŒ— Toggle between light and dark themes with icon switch (â˜€ï¸ / ğŸŒ™)

---


## ğŸ“¸ Demo Preview

> Home 
![alt text](Home.png)

> API Summary 
![alt text](API_Summary.png)

> Web Summary
![alt text](Web_Summary.png)

### ğŸ“Š Visual Enhancements (Phase 1 Update)
- Added automatic bar chart generation after CSV cleanup
- Separate charts for API and Web files saved under `static`
- UI now supports toggling between light/dark themes with AI summaries + insights


### ğŸ“Š API Bar Chart
![API Chart](report_html/visuals/Bar_API.png)

### ğŸ“Š Web Bar Chart
![Web Chart](report_html/visuals/Bar_Web.png)

### ğŸ¥§ API Pie Chart
![API Pie](report_html/visuals/PI_API.png)

### ğŸ¥§ Web Pie Chart
![Web Pie](report_html/visuals/PI_Web.png)

### ğŸ¥§ Individual File Summary
![Individual File Summary](report_html/visuals/Individual_File_Summary.png)

>Q & A 
![AI Chat](report_html/visuals/AI_Chat.png)


### ğŸ¥§ File Compare
![File Compare](report_html/visuals/File_compare.png)

---
```

## ğŸ“ Folder Structure

```bash
ai_report_automation_advanced/
â”œâ”€â”€ app.py # Flask app entry point
â”œâ”€â”€ main.py # Master pipeline logic
â”œâ”€â”€ api_downloader.py
â”œâ”€â”€ web_downloader.py
â”œâ”€â”€ file_extractor.py
â”œâ”€â”€ data_cleaner.py
â”œâ”€â”€ ai_summary.py # Summary generation with LLM
â”œâ”€â”€ question_answering.py # Q&A logic
â”œâ”€â”€ report_generator.py
â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ index.html # UI with dark mode + toggle
â”‚ â””â”€â”€ report_template.html # HTML report
â”œâ”€â”€ static/
â”‚ â”œâ”€â”€ bar_chart_api.png
â”‚ â””â”€â”€ bar_chart_web
â”œâ”€â”€ input_data/
â”‚ â”œâ”€â”€ api/ # API downloaded CSV
â”‚ â””â”€â”€ web/ # Web ZIPs & CSV
â”œâ”€â”€ output_reports/
â”‚ â”œâ”€â”€ api/clear_api.csv
â”‚ â””â”€â”€ web/clear_web.csv
â”œâ”€â”€ config/.env # FTP settings (optional)

---
```
## âš™ï¸ Requirements


- Python 3.10+
- Google Chrome
- [Ollama](https://ollama.com/download) (for local LLMs)
- ChromeDriver (version matching your Chrome)
- Git (for cloning)

---

## ğŸ› ï¸ Installation

### 1. Clone the repo
```
```bash
git clone https://github.com/your-username/smartfile-ai.git
cd smartfile-ai
```


---
```
2. Create Virtual Environment

python -m venv venv
venv\Scripts\activate   # On Windows
# source venv/bin/activate   # On Linux/macOS
```

```
3. Install Requirements

pip install -r requirements.txt

If no requirements.txt, run:

pip freeze > requirements.txt
```

---
```
ğŸ” Environment Setup (.env)
Create a file at config/.env and add:


ftp_server=example.com
ftp_ip=192.168.1.1
ftp_port=21
ftp_user=youruser
ftp_pass=yourpass
```
---
```
ğŸ¤– Ollama Setup

1. Install Ollama
Download from: https://ollama.com/download
(Available for Windows, macOS, Linux)
```
---
```
2. Pull a Model

ollama pull mistral
Alternatives:

llama3

tinyllama

phi3
```
---

```
3. Start the Model

ollama run mistral
ğŸ§  Update Model in Code
In both ai_summary.py & question_answering.py, make sure the model is:


"model": "mistral"
```
---
```
ğŸš€ Start the Flask App

python app.py
App runs at:
ğŸ”— http://127.0.0.1:5000
```
---
```
# Terminal - Ollama
ollama run mistral or any other
```
